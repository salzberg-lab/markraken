{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"test marker representation on sample sequences\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mmh3\n",
    "import pickle\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data paths\n",
    "data_dir = '/ccb/salz4-4/markus/markraken/data'\n",
    "\n",
    "seq_pickle_path = os.path.join(data_dir, 'DB.pkl')\n",
    "HPC_pickle_path = os.path.join(data_dir, 'DB_HPC.pkl')\n",
    "hashtable_path = os.path.join(data_dir, 'index.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(seq_pickle_path, 'rb') as f:\n",
    "    seq_list = pickle.load(f)\n",
    "\n",
    "with open(HPC_pickle_path, 'rb') as f:\n",
    "    HPC_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_markers = 8000 # number of markers to use for representation of sequence as markers, Shasta default = 8000\n",
    "marker_length = 10 # length of marker sequence, Shasta default = 10\n",
    "\n",
    "# randomly select marker set without replacement, surprisingly complex to vectorize, works fast enough like this\n",
    "random.seed(2019)\n",
    "marker_set = set()\n",
    "while len(marker_set) < n_markers:\n",
    "    marker = [random.sample('ATCG', 1)[0]]\n",
    "    for i in range(marker_length-1):\n",
    "        nucs = {'A', 'T', 'C', 'G'}\n",
    "        nucs.remove(marker[-1])\n",
    "        marker.append(random.sample(nucs, 1)[0])\n",
    "    marker_set.add(''.join(marker))\n",
    "\n",
    "marker_list = list(marker_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO sample while considering reverse complement to ensure easy searches regardless of strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5976\n",
      "558\n"
     ]
    }
   ],
   "source": [
    "# extract markers from homopolymer compressed sequence\n",
    "# TODO temprorary code here, marker finding can definitely be improved a lot\n",
    "def markerize(HPC_seq):\n",
    "    marker_seq = []\n",
    "    for i in range(len(HPC_seq)):\n",
    "        subseq = HPC_seq[i:i+marker_length]\n",
    "        try:\n",
    "            idx = marker_list.index(subseq)\n",
    "            marker_seq.append(idx)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return marker_seq\n",
    "\n",
    "foo = markerize(HPC_list[0])\n",
    "print(len(HPC_list[0]))\n",
    "print(len(foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threads = 20\n",
    "\n",
    "# markerize all HPC seqs\n",
    "p = mp.Pool(n_threads)\n",
    "markerized_list = p.map(markerize, HPC_list)\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to tuple to allow hashing\n",
    "markerized_chrlist = [''.join([chr(s) for s in x]) for x in markerized_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 s, sys: 460 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # extract marKmers (short kmers with much larger alphabet) from marker sequences\n",
    "# # marKmer uniqueness is roughly equivalent to a normal kmer of length = marKmer_length*marker_length\n",
    "# # e.g. with marker length 10, marKmer 3 ~ kmer 30\n",
    "# marKmer_length = 4\n",
    "# hash_seed = 2019\n",
    "\n",
    "# marKmer_hashtable = dict()\n",
    "# for i, m in enumerate(markerized_chrlist): # i is stand-in for true taxid, TODO handle taxid with LCA\n",
    "#     marKmer_set = set()\n",
    "#     for i in range(len(m)):\n",
    "#         subseq = m[i:i+marKmer_length] # this might be slow, TODO check if this slices or copies\n",
    "#         marKmer_set.add(subseq) # adding to set is O(1)\n",
    "        \n",
    "#     hashlist = [mmh3.hash(x, hash_seed) for x in list(marKmer_set)]\n",
    "#     tmp_dict = dict(zip(hashlist, [i]*len(hashlist)))\n",
    "#     marKmer_hashtable.update(tmp_dict)\n",
    "    \n",
    "###### slower in 1 thread, but easier to parallelize in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.73 s, sys: 485 ms, total: 9.22 s\n",
      "Wall time: 9.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# extract marKmers (short kmers with much larger alphabet) from marker sequences\n",
    "# marKmer uniqueness is roughly equivalent to a normal kmer of length = marKmer_length*marker_length\n",
    "# e.g. with marker length 10, marKmer 3 ~ kmer 30\n",
    "marKmer_length = 4\n",
    "hash_seed = 2019\n",
    "\n",
    "marKmer_hashtable = dict()\n",
    "for i, m in enumerate(markerized_chrlist): # i is stand-in for true taxid, TODO handle taxid with LCA\n",
    "    marKmer_set = set()\n",
    "    for i in range(len(m)):\n",
    "        subseq = m[i:i+marKmer_length] # this might be slow, TODO check if this slices or copies\n",
    "        marKmer_set.add(subseq) # adding to set is O(1)\n",
    "    for m in marKmer_set:\n",
    "        marKmer_hashtable.update({m:i}) # TODO check if adding to dict is O(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index\n",
    "with open(hashtable_path, 'wb') as f:\n",
    "    pickle.dump(marKmer_hashtable, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209241084 gigabytes for index\n",
      "0.116762843 Gbp of sequence\n"
     ]
    }
   ],
   "source": [
    "# examine compression ratio\n",
    "singleseq = ''.join(seq_list)\n",
    "print(len(pickle.dumps(marKmer_hashtable))/1e9, 'gigabytes for index') # guaranteed conservative estimate of object size\n",
    "print(len(pickle.dumps(singleseq))/1e9, 'Gbp of sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO examine accuracy in perfect reads\n",
    "#TODO examine accuracy as a function of sequencing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenlist = [len(x) for x in markerized_list]\n",
    "plt.hist(lenlist)\n",
    "plt.show()\n",
    "print(np.sum(np.asarray(lenlist)>10000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
